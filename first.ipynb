{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "from pinecone import Pinecone as pc_client\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "# from langchain.vectorstores import Pinecone as Pineconestore\n",
    "from langchain_core.messages import AIMessage,HumanMessage,SystemMessage\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# from pinecone import Pinecone as pc_client, ServerlessSpec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file from a specific path\n",
    "path = os.path.join(os.getcwd(),'.env')\n",
    "load_dotenv(dotenv_path=path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_doc(directory):\n",
    "  file_object = PyPDFDirectoryLoader(directory)\n",
    "  file = file_object.load()\n",
    "  # print(file)\n",
    "  return file\n",
    "\n",
    "file = read_doc(\"D:/look_at_me/krish_pine_folder/krish_pine/papers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('id', None)\n",
      "('metadata', {'source': 'D:\\\\look_at_me\\\\krish_pine_folder\\\\krish_pine\\\\papers\\\\Kim_Cluster_Self-Refinement_for_Enhanced_Online_Multi-Camera_People_Tracking_CVPRW_2024_paper.pdf', 'page': 1, 'page_label': '2'})\n",
      "('page_content', 'Figure 2. Overview of our system’s architecture.\\nonline MCPT.\\nOnline MCPT, unlike offline MCPT, must predict the\\ntracking results of the current frame solely based on ac-\\ncumulated information from past frames. Therefore, if in-\\ncorrect information is stored or tracking is done wrongly at\\nany point, this misinformation can accumulate, leading to\\nrepeated errors in the results. First, if inaccurate or low-\\nquality appearance features are stored, it confuses predict-\\ning the results of subsequent frames and makes accurate\\ntracking difficult. The second issue arises when more than\\none global ID is assigned to the same person. In situations\\nwhere a new person enters a given location or an existing\\nperson disappears, a new global ID can be assigned to the\\nsame person. Traditional online MCPT systems cannot ad-\\ndress these issues, leading to the continuous assignment of\\ndifferent global IDs and, consequently, inaccurate tracking.\\nIn this study, to overcome these limitations of pre-\\nvious MCPT implementations, we propose Cluster Self-\\nRefinement (CSR), a method that periodically cleanses and\\ncorrects the stored appearance information and assigned\\nGlobal IDs. Moreover, we have enhanced the utilization\\nof the pose estimation model to enable more accurate loca-\\ntion estimation and the storage of a wider variety of higher-\\nquality appearance information. Our experimental results\\nshow that we achieved significant performance improve-\\nments through CSR and further enhancements via pose esti-\\nmation usage, achieving a HOTA score of 60.9261% on the\\nofficial test dataset, which allowed us to secure third place\\nin the 2024 AI City Challenge Track 1.\\n2. Related work\\nMulti-camera multi-object tracking (MCMT) has been re-\\nsearched across various domains in recent years, includ-\\ning vehicle tracking [26] and people tracking [7, 8, 11,\\n13, 17, 19, 25]. Regardless of the domain, most MCMT\\nsystems consist of processes for object detection, single-\\ncamera tracking, and inter-camera association.\\n2.1. Object Detection\\nThe performance of the object detection model is crucial\\nin MCMT. This is because accurate bounding box predic-\\ntions are essential for extracting precise appearance and lo-\\ncation information. Various models have been researched\\nto enable real-time usage, including those based on the\\nYou Only Look Once (YOLO)[10, 12, 22] methodology,\\ntwo-stage models based on the Region Proposal Network\\n(RPN) such as the R-CNN family[4–6, 18], and more re-\\ncently, models based on the Transformer block, represent-\\ning the state-of-the-art, such as Detection with Transformer\\n(DETR)[3, 26, 28].\\n2.2. Multi-Object Single Camera Tracking\\nSingle-camera tracking is a system that utilizes detection\\nresults to assign IDs to bounding boxes, thereby identi-\\nfying trajectories. Research in this area continues to be\\nactively conducted, with recent developments focusing on\\nmethods to prevent ID-switches, particularly those based on\\nthe Re-ID model proposed in DeepSort[21]. Models such\\nas ByteTrack[27], OC-Sort[2], and BoT-Sort[1] have been\\nintroduced, building on this foundation.\\n2.3. Multi Camera People Tracking\\nMulti-camera people tracking (MCPT) is a task within\\nMCMT focused on the people domain. This task is pre-\\nsented in the 2024 AI City Challenge Track 1 [24] , in\\nwhich we participated this year, continuing the same task\\n7191\\n')\n",
      "('type', 'Document')\n"
     ]
    }
   ],
   "source": [
    "len(file) , type(file)\n",
    "for e in file[1]:\n",
    "  print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunked(docs, chunk_size, chunk_overlap):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size = chunk_size,chunk_overlap = chunk_overlap)\n",
    "  #  [\"\\n\\n\", \"\\n\", \" \", \"\"] by default splitting based on these\n",
    "  chunks = text_splitter.split_documents(docs)\n",
    "  return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_data = chunked(docs=file,chunk_size=100,chunk_overlap=20)\n",
    "# for e in file[1]:\n",
    "#   print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'D:\\\\look_at_me\\\\krish_pine_folder\\\\krish_pine\\\\papers\\\\Kim_Cluster_Self-Refinement_for_Enhanced_Online_Multi-Camera_People_Tracking_CVPRW_2024_paper.pdf', 'page': 0, 'page_label': '1'}, page_content='Cluster Self-Refinement for Enhanced Online Multi-Camera People Tracking')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_data)\n",
    "type(chunked_data)\n",
    "chunked_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\look_at_me\\krish_pine_folder\\krish_pine\\pineenv\\Lib\\site-packages\\langchain_mistralai\\embeddings.py:180: UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "embeddings  = MistralAIEmbeddings(api_key=os.environ['MISTRAL_API_KEY'])\n",
    "\n",
    "# testing_embeddings\n",
    "string = \"hi this is jai lets see the dimensions\"\n",
    "vector = embeddings.embed_query(string)\n",
    "print(len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cluster Self-Refinement for Enhanced Online Multi-Camera People Tracking'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(file[1])\n",
    "# file[7]\n",
    "# file[0]\n",
    "# len(file)\n",
    "# for i in range(len(file)):\n",
    "#   print(file[i].page_content)\n",
    "chunked_data[0].page_content\n",
    "# len(chunked_data)\n",
    "# chunked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"id\": f\"vec{i+1}\", \"text\": text.page_content} for i, text in enumerate(chunked_data)]\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred with MistralAI: Client error '429 Too Many Requests' for url 'https://api.mistral.ai/v1/embeddings'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n"
     ]
    },
    {
     "ename": "HTTPStatusError",
     "evalue": "Client error '429 Too Many Requests' for url 'https://api.mistral.ai/v1/embeddings'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m only_content \u001b[38;5;241m=\u001b[39m [d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# type(only_content)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m embeddings_chunk \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43monly_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# li = [d['text'] for d in data]\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# li\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# len(data[0]['text'])\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# emb = embeddings.embed_query(['hi'])\u001b[39;00m\n",
      "File \u001b[1;32md:\\look_at_me\\krish_pine_folder\\krish_pine\\pineenv\\Lib\\site-packages\\langchain_mistralai\\embeddings.py:242\u001b[0m, in \u001b[0;36mMistralAIEmbeddings.embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_batches(texts):\n\u001b[1;32m--> 242\u001b[0m         batch_responses\u001b[38;5;241m.\u001b[39mappend(\u001b[43m_embed_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, embedding_obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m batch_responses\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m embedding_obj \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    247\u001b[0m     ]\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\look_at_me\\krish_pine_folder\\krish_pine\\pineenv\\Lib\\site-packages\\tenacity\\__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\look_at_me\\krish_pine_folder\\krish_pine\\pineenv\\Lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\look_at_me\\krish_pine_folder\\krish_pine\\pineenv\\Lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\look_at_me\\krish_pine_folder\\krish_pine\\pineenv\\Lib\\site-packages\\tenacity\\__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\look_at_me\\krish_pine_folder\\krish_pine\\pineenv\\Lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32md:\\look_at_me\\krish_pine_folder\\krish_pine\\pineenv\\Lib\\site-packages\\langchain_mistralai\\embeddings.py:238\u001b[0m, in \u001b[0;36mMistralAIEmbeddings.embed_documents.<locals>._embed_batch\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;129m@retry\u001b[39m(\n\u001b[0;32m    226\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry_if_exception_type(httpx\u001b[38;5;241m.\u001b[39mTimeoutException),\n\u001b[0;32m    227\u001b[0m     wait\u001b[38;5;241m=\u001b[39mwait_fixed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_time),\n\u001b[0;32m    228\u001b[0m     stop\u001b[38;5;241m=\u001b[39mstop_after_attempt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries),\n\u001b[0;32m    229\u001b[0m )\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_embed_batch\u001b[39m(batch: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[0;32m    231\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mpost(\n\u001b[0;32m    232\u001b[0m         url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    233\u001b[0m         json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m         ),\n\u001b[0;32m    237\u001b[0m     )\n\u001b[1;32m--> 238\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\look_at_me\\krish_pine_folder\\krish_pine\\pineenv\\Lib\\site-packages\\httpx\\_models.py:763\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m error_type \u001b[38;5;241m=\u001b[39m error_types\u001b[38;5;241m.\u001b[39mget(status_class, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid status code\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    762\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[1;32m--> 763\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.mistral.ai/v1/embeddings'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429"
     ]
    }
   ],
   "source": [
    "only_content = [d['text'] for d in data]\n",
    "# type(only_content)\n",
    "embeddings_chunk = embeddings.embed_documents(only_content)\n",
    "# li = [d['text'] for d in data]\n",
    "# li\n",
    "# len(data[0]['text'])\n",
    "# emb = embeddings.embed_query(['hi'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred with MistralAI: Client error '429 Too Many Requests' for url 'https://api.mistral.ai/v1/embeddings'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit hit. Retrying in 1 seconds...\n"
     ]
    }
   ],
   "source": [
    "# Using exponential backoff\n",
    "import time\n",
    "\n",
    "def embed_with_retries(embeddings, texts, retries=5):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            return embeddings.embed_documents(texts)\n",
    "        except Exception as e:\n",
    "            if \"429\" in str(e):\n",
    "                wait_time = 2 ** i  # Exponential backoff\n",
    "                print(f\"Rate limit hit. Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "embeddings_chunk = embed_with_retries(embeddings, only_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings_chunk\n",
    "type(embeddings_chunk)\n",
    "len(embeddings_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"krish-vector\"\n",
    "pc = pc_client(api_key=os.environ['PINE'])\n",
    "index = pc.Index(index_name) # Target the index where you'll store the vector embeddings\n",
    "\n",
    "# print(pc,index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Prepare the records for upsert\n",
    "# Each contains an 'id', the embedding 'values', and the original text as 'metadata'\n",
    "records = []\n",
    "for d, e in zip(data, embeddings_chunk):\n",
    "    records.append({\n",
    "        \"id\": d['id'],\n",
    "        \"values\": e,\n",
    "        \"metadata\": {'text': d['text']}\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 520}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.upsert(\n",
    "    vectors=records,\n",
    "    namespace=\"example-namespace\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def best_results(query):\n",
    "    embedded_query = embeddings.embed_query(query)\n",
    "    # embedded_query\n",
    "    results = index.query(\n",
    "        namespace=\"example-namespace\",\n",
    "        vector=embedded_query,\n",
    "        top_k=3,\n",
    "        include_values=False,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['on Multi-Camera People Tracking (MCPT). MCPT presents', 'an online Multi-Camera People Tracking (MCPT) system', 'Figure 1. This is an example of Multi-Camera People Tracking. It']\n"
     ]
    }
   ],
   "source": [
    "# type(results)\n",
    "query = \"what is multicamera people tracking?\"\n",
    "response = best_results(query)\n",
    "texts = [match['metadata']['text'] for match in response['matches']]\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': 'vec5',\n",
       "              'metadata': {'text': 'on Multi-Camera People Tracking (MCPT). '\n",
       "                                   'MCPT presents'},\n",
       "              'score': 0.839963,\n",
       "              'values': []},\n",
       "             {'id': 'vec152',\n",
       "              'metadata': {'text': 'an online Multi-Camera People Tracking '\n",
       "                                   '(MCPT) system'},\n",
       "              'score': 0.834228694,\n",
       "              'values': []},\n",
       "             {'id': 'vec38',\n",
       "              'metadata': {'text': 'Figure 1. This is an example of '\n",
       "                                   'Multi-Camera People Tracking. It'},\n",
       "              'score': 0.829051673,\n",
       "              'values': []}],\n",
       " 'namespace': 'example-namespace',\n",
       " 'usage': {'read_units': 6}}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided information, it seems there are several authors with the name \"Narendra\" mentioned in the context of computer vision research. However, without more specific context or information, it's not possible to determine if any of these authors are referring to the same person named \"Narendra Mode.\"\n",
      "\n",
      "Here's a brief overview of the authors mentioned:\n",
      "\n",
      "1. Meenakshi S. Rahman and other authors have published a paper titled \"Multi-modal Sentiment Analysis on Social Media: A Review\" in 2021.\n",
      "2. Balaji Veeramani, John W. Raymond, and Pritam Chanda have published a paper titled \"A Survey on Deep Learning for Computer Vision\" in 2020.\n",
      "3. Chengqi Lyu, Yining Li, and Kai Chen have published a paper titled \"Rtmpose: Real-time Multi-pose Human Pose Estimation with Convolutional Neural Networks\" in 2018.\n",
      "\n",
      "Unfortunately, based on the information provided, it's not clear if any of these authors are the person you were asking about. If you have more specific information or context, I'd be happy to help further!\n",
      "\n",
      "(Sorry but no info available in the docs)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatMistralAI(model_name=\"open-mistral-7b\")\n",
    "query = \"who is narendra mode?\"\n",
    "def get_text(response):\n",
    "  texts = [match['metadata']['text'] for match in response['matches']]\n",
    "  return texts\n",
    "\n",
    "relevant_ans_meta = best_results(query)\n",
    "relevant_ans = get_text(relevant_ans_meta)\n",
    "  \n",
    "combined_input = ('my question is' + query +'here are some information that might be helpful \\n\\n '+ '\\n\\n'.join(ans for ans in relevant_ans)\n",
    "+ \"\\n\\nplease provide answer with the help of this relevant the inputs provided if answer is not availabe  in this query then return : sorry but no info available in the docs\")\n",
    "\n",
    "# print(combined_input)\n",
    "messages = [\n",
    " SystemMessage(content='You are expert researcher in computer vision'),\n",
    " HumanMessage(content=combined_input)\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pineenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
